{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dictionaries to analyse events.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import create_dicts\n",
    "\n",
    "\n",
    "code_path = os.getcwd()\n",
    "data_path = \"C:/Users/XHK/Desktop/thesis_code/events_analysis/data/raw/kaggle\"\n",
    "\n",
    "event_type1, event_type2, side, shot_place, shot_outcome, location, \\\n",
    "    bodypart, assist_method, situation = create_dicts.get_dictionaries()\n",
    "\n",
    "\n",
    "weighted_attempts_filename = \"events_w_weighted_french_logistic.csv\" # \"events_w_weighted_french.csv\"\n",
    "events = pd.read_csv('/'.join([data_path, weighted_attempts_filename]))\n",
    "ginf = pd.read_csv('/'.join([data_path, \"ginf.csv\"]))\n",
    "\n",
    "events_columns = ['id_odsp', 'id_event', 'sort_order', 'time', 'text', 'event_type',\n",
    "                  'event_type2', 'side', 'event_team', 'opponent', 'player', 'player2',\n",
    "                  'player_in', 'player_out', 'shot_place', 'shot_outcome', 'is_goal',\n",
    "                  'location', 'bodypart', 'assist_method', 'situation', 'fast_break']\n",
    "\n",
    "ginf_columns = ['id_odsp', 'link_odsp', 'adv_stats', 'date', 'league', 'season',\n",
    "                'country', 'ht', 'at', 'home_goals', 'away_goals', 'odd_h', 'odd_d', 'odd_a',\n",
    "                'odd_over', 'odd_under', 'odd_bts', 'odd_bts_n'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\XHK\\\\Desktop\\\\thesis_code\\\\events_analysis\\\\src\\\\features'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code to determine which league is best to start analysing: \n",
    "\n",
    "the variable ginf is a DataFrame created from a .csv which stores general info about each match in the 'events' dataset\n",
    "\n",
    "We want detailed match-data, which means the match must have adv_stats == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id_odsp</th>\n",
       "      <th>link_odsp</th>\n",
       "      <th>date</th>\n",
       "      <th>season</th>\n",
       "      <th>country</th>\n",
       "      <th>ht</th>\n",
       "      <th>at</th>\n",
       "      <th>fthg</th>\n",
       "      <th>ftag</th>\n",
       "      <th>odd_h</th>\n",
       "      <th>odd_d</th>\n",
       "      <th>odd_a</th>\n",
       "      <th>odd_over</th>\n",
       "      <th>odd_under</th>\n",
       "      <th>odd_bts</th>\n",
       "      <th>odd_bts_n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adv_stats</th>\n",
       "      <th>league</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">False</th>\n",
       "      <th>D1</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E0</th>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I1</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP1</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">True</th>\n",
       "      <th>D1</th>\n",
       "      <td>1641</td>\n",
       "      <td>1641</td>\n",
       "      <td>1641</td>\n",
       "      <td>1641</td>\n",
       "      <td>1641</td>\n",
       "      <td>1641</td>\n",
       "      <td>1641</td>\n",
       "      <td>1641</td>\n",
       "      <td>1641</td>\n",
       "      <td>1641</td>\n",
       "      <td>1641</td>\n",
       "      <td>1641</td>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E0</th>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I1</th>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>2088</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP1</th>\n",
       "      <td>2065</td>\n",
       "      <td>2065</td>\n",
       "      <td>2065</td>\n",
       "      <td>2065</td>\n",
       "      <td>2065</td>\n",
       "      <td>2065</td>\n",
       "      <td>2065</td>\n",
       "      <td>2065</td>\n",
       "      <td>2065</td>\n",
       "      <td>2065</td>\n",
       "      <td>2065</td>\n",
       "      <td>2065</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id_odsp  link_odsp  date  season  country    ht    at  fthg  \\\n",
       "adv_stats league                                                                \n",
       "False     D1           49         49    49      49       49    49    49    49   \n",
       "          E0          820        820   820     820      820   820   820   820   \n",
       "          F1           19         19    19      19       19    19    19    19   \n",
       "          I1           18         18    18      18       18    18    18    18   \n",
       "          SP1          24         24    24      24       24    24    24    24   \n",
       "True      D1         1641       1641  1641    1641     1641  1641  1641  1641   \n",
       "          E0         1300       1300  1300    1300     1300  1300  1300  1300   \n",
       "          F1         2088       2088  2088    2088     2088  2088  2088  2088   \n",
       "          I1         2088       2088  2088    2088     2088  2088  2088  2088   \n",
       "          SP1        2065       2065  2065    2065     2065  2065  2065  2065   \n",
       "\n",
       "                  ftag  odd_h  odd_d  odd_a  odd_over  odd_under  odd_bts  \\\n",
       "adv_stats league                                                            \n",
       "False     D1        49     49     49     49         0          0        0   \n",
       "          E0       820    820    820    820         0          0        0   \n",
       "          F1        19     19     19     19         0          0        0   \n",
       "          I1        18     18     18     18         0          0        0   \n",
       "          SP1       24     24     24     24         0          0        0   \n",
       "True      D1      1641   1641   1641   1641       153        153      153   \n",
       "          E0      1300   1300   1300   1300       220        220      220   \n",
       "          F1      2088   2088   2088   2088       208        208      208   \n",
       "          I1      2088   2088   2088   2088       207        207      207   \n",
       "          SP1     2065   2065   2065   2065       189        189      189   \n",
       "\n",
       "                  odd_bts_n  \n",
       "adv_stats league             \n",
       "False     D1              0  \n",
       "          E0              0  \n",
       "          F1              0  \n",
       "          I1              0  \n",
       "          SP1             0  \n",
       "True      D1            153  \n",
       "          E0            220  \n",
       "          F1            208  \n",
       "          I1            207  \n",
       "          SP1           189  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ginf.groupby(['adv_stats', 'league']).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "France and Italy have the most matches with available events-data in the dataset. \n",
    "We pick the French league arbitrarily, moving forward.\n",
    "\n",
    "first we want to have a column for home-goal-attempts and away-goal-attempts and add it to ginf. \n",
    "attempt has an event_type of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_no_stats_fr = ginf[(ginf.league == 'F1') & (ginf.adv_stats == False)]\n",
    "\n",
    "matches_fr = ginf[(ginf.adv_stats == True) & (ginf.league == 'F1')]\n",
    "events_fr = events.loc[events.id_odsp.isin(matches_fr.id_odsp)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of attempts by either team. own-goals are ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the amount of attempts on goal by the home-team and by the away-team. \n",
    "There are around 12 NaN's in those columns. We will deal with them by using the average amount of attempts of the corresponding teams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#matches_fr['home_attempts'] = np.nan\n",
    "#matches_fr['away_attempts'] = np.nan\n",
    "\n",
    "h_att = events_fr[(events_fr.event_type == 1) & (\n",
    "        events_fr.side == 1) &(event_type2 != 15)].groupby('id_odsp').count()\n",
    "\n",
    "a_att = events_fr[(events_fr.event_type == 1) & (\n",
    "    events_fr.side == 2) & (event_type2 != 15)].groupby('id_odsp').count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_fr.index = matches_fr.id_odsp\n",
    "matches_fr = pd.concat([matches_fr,h_att.event_type],   axis = 1)\n",
    "matches_fr = matches_fr.rename({'event_type':'home_attempts' }, axis='columns')\n",
    "matches_fr = pd.concat([matches_fr,a_att.event_type],   axis = 1)\n",
    "matches_fr = matches_fr.rename({'event_type':'away_attempts'}, axis='columns')\n",
    "\n",
    "#matches_fr.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matches_fr = matches_fr.rename({'fthg': 'home_goals'}, axis='columns')\n",
    "matches_fr = matches_fr.rename({'ftag': 'away_goals'}, axis='columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replacing NaNs  in Home_- and Away_attempts  with the average over all games (this causes minor information-leak from future values to past values, but only around 19 NaNs in the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_nans = matches_fr[matches_fr.home_attempts.isna()]['ht']\n",
    "away_nans = matches_fr[matches_fr.away_attempts.isna()]['at']\n",
    "\n",
    "\n",
    "# homers = home_nans.values\n",
    "# for team in homers:\n",
    "#     matches_fr[matches_fr.ht == team].home_attempts.mean()\n",
    "#home_nans\n",
    "\n",
    "for game_id,team in home_nans.iteritems():\n",
    "    mean_att = matches_fr[matches_fr.ht == team].home_attempts.mean()\n",
    "    matches_fr.loc[matches_fr.id_odsp == game_id, 'home_attempts'] = mean_att\n",
    "for game_id, team in away_nans.iteritems():\n",
    "    mean_att = matches_fr[matches_fr['at'] == team].away_attempts.mean()\n",
    "    matches_fr.loc[matches_fr.id_odsp == game_id, 'away_attempts'] = mean_att\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed by getting the amount of red card events:\n",
    "In the events.csv, 'location'\n",
    "\n",
    "First we define a helper function:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing 1953 NaNs by 0 for event =  redcard\n"
     ]
    }
   ],
   "source": [
    "def get_events(events, event_type_nr, type=1 ):\n",
    "    event_type = 'event_type'\n",
    "    if type != 1:\n",
    "        event_type= 'event_type2'\n",
    "    h_events = events[(events[event_type] == event_type_nr) & (\n",
    "        events.side == 1)].groupby('id_odsp').count()\n",
    "\n",
    "\n",
    "    a_events = events[(events[event_type] == event_type_nr) & (\n",
    "        events.side == 2)].groupby('id_odsp').count()\n",
    "\n",
    "    return h_events, a_events\n",
    "\n",
    "def concat_and_rename(df_matches, home_vec, away_vec, name, type = 1):\n",
    "    event_type = 'event_type'\n",
    "    if type != 1:\n",
    "        event_type = 'event_type2'\n",
    "    \n",
    "\n",
    "    home_name = 'home_'+name\n",
    "    away_name = 'away_'+name \n",
    "    df_matches.index = df_matches.id_odsp\n",
    "\n",
    "    df_matches = pd.concat([df_matches, home_vec[event_type]],   axis=1)\n",
    "    df_matches = df_matches.rename({event_type: home_name}, axis='columns')\n",
    "    df_matches = pd.concat([df_matches, away_vec[event_type]],   axis=1)\n",
    "    df_matches = df_matches.rename({event_type: away_name}, axis='columns')\n",
    "\n",
    "    # changing nans to zeroes:\n",
    "    if name == 'offsides' or name == 'yellowcards':  # Offsides-variable displays NaN when no offside-events registered. 0 offsides is still realistic occurence.\n",
    "        print(\n",
    "            f\"replacing {sum(df_matches[home_name].isna())} NaNs by {0} for event =  {name}\")\n",
    "        df_matches.loc[df_matches[home_name].isna(), home_name] = 0\n",
    "        df_matches.loc[df_matches[away_name].isna(), away_name] = 0\n",
    "        return df_matches\n",
    "    else: #changing NaNs for some variables into the overall mean for that variable in the dataset\n",
    "        print(f\"replacing {sum(df_matches[home_name].isna())} NaNs by {int(df_matches[home_name].fillna(0).mean())} for event =  {name}\")\n",
    "        #print(f\"{set(df_matches[df_matches[home_name].isna()]['ht'])}\")\n",
    "        df_matches.loc[df_matches[home_name].isna(), home_name] = int(\n",
    "            df_matches[home_name].fillna(0).mean())\n",
    "        df_matches.loc[df_matches[away_name].isna(), away_name] = int(\n",
    "            df_matches[away_name].fillna(0).mean())\n",
    "        return df_matches\n",
    "\n",
    "home_redcard,away_redcard = get_events(events_fr, 6)\n",
    "matches_fr = concat_and_rename(matches_fr, home_redcard, away_redcard, name = 'redcard')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changing all the NaN's to 0 red_card values: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the 'conceded penalty' feature:       penalty_conceded has eventnumber 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing 1759 NaNs by 0 for event =  penalty_conceded\n"
     ]
    }
   ],
   "source": [
    "home_penalty_conceded, away_penalty_conceded = get_events(events_fr, 11)\n",
    "matches_fr = concat_and_rename(    matches_fr, home_penalty_conceded, away_penalty_conceded, name='penalty_conceded')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(matches_fr.home_redcard.isna())\n",
    "\n",
    "#matches_fr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding columns for a home_sentoff and away_sentoff features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing 1886 NaNs by 0 for event =  sentoff\n"
     ]
    }
   ],
   "source": [
    "home_sent, away_sent = get_events(events_fr, 14, type=2)\n",
    "matches_fr = concat_and_rename(    matches_fr, home_sent, away_sent, name='sentoff')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding corner_taken features for both teams.   Corners conceded is lower for away team???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing 38 NaNs by 5 for event =  corners_taken\n"
     ]
    }
   ],
   "source": [
    "home_corner, away_corner = get_events(events_fr, 2, type = 1)\n",
    "matches_fr = concat_and_rename(\n",
    "    matches_fr, home_corner, away_corner, name='corners_taken')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fouls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing 14 NaNs by 12 for event =  fouls\n"
     ]
    }
   ],
   "source": [
    "home_fouls, away_fouls = get_events(events_fr, 3, type=1)\n",
    "matches_fr = concat_and_rename(    matches_fr, home_fouls, away_fouls, name='fouls')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing 14 NaNs by 13 for event =  free_kicks\n"
     ]
    }
   ],
   "source": [
    "home_free_kicks, away_free_kicks = get_events(events_fr, 8 ,type=1 )\n",
    "matches_fr = concat_and_rename(matches_fr, home_free_kicks, away_free_kicks, name = 'free_kicks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing 1063 NaNs by 0 for event =  handballs\n"
     ]
    }
   ],
   "source": [
    "home_handballs, away_handballs = get_events(events_fr, 10)\n",
    "matches_fr = concat_and_rename(matches_fr, home_handballs, away_handballs, name = 'handballs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing 292 NaNs by 0 for event =  offsides\n"
     ]
    }
   ],
   "source": [
    "home_offsides, away_offsides = get_events(events_fr, 9)\n",
    "matches_fr = concat_and_rename(\n",
    "    matches_fr, home_offsides, away_offsides, name='offsides')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing 1993 NaNs by 0 for event =  own_goals\n"
     ]
    }
   ],
   "source": [
    "away_own_goal, home_own_goal  = get_events(events_fr, 15, type = 2)  #away, home switched around because an own_goal commited by home team, is credited to the 'side'-variable of away_team\n",
    "matches_fr = concat_and_rename(\n",
    "    matches_fr, away_own_goal, home_own_goal, name='own_goals')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing 327 NaNs by 0 for event =  yellowcards\n"
     ]
    }
   ],
   "source": [
    "home_yellows, away_yellows = get_events(events_fr, 4)\n",
    "matches_fr = concat_and_rename(\n",
    "    matches_fr, home_yellows, away_yellows, name='yellowcards')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[] Use shot-placement, location and isGoal to determine a weighting for attempts\n",
    "    [use logistic-regression]\n",
    "[] Make a weighted-attempts feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countt(probabilities,threshold=0.26):\n",
    "    return sum(probabilities > threshold)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the French attempt-events that did not end in own-goals\n",
    " \n",
    "french_attempt_events = events[(events.id_odsp.isin(matches_fr.id_odsp)) & (events.event_type ==1) & (events.event_type2 !=15)]\n",
    "french_attempt_events.groupby('id_odsp side'.split()).sum()\n",
    "\n",
    "home_weighted_attempts = french_attempt_events[french_attempt_events.side == 1].groupby(\n",
    "    'id_odsp').sum().french_attempt_weight\n",
    "\n",
    "away_weighted_attempts = french_attempt_events[french_attempt_events.side == 2].groupby('id_odsp').sum().french_attempt_weight\n",
    "\n",
    "matches_fr = pd.concat([matches_fr, home_weighted_attempts],   axis=1)\n",
    "matches_fr = matches_fr.rename(\n",
    "    {'french_attempt_weight': 'home_weighted_attempts'}, axis='columns')\n",
    "matches_fr = pd.concat([matches_fr, away_weighted_attempts],   axis=1)\n",
    "matches_fr = matches_fr.rename(\n",
    "    {'french_attempt_weight': 'away_weighted_attempts'}, axis='columns')\n",
    "\n",
    "# changing nans to zeroes:\n",
    "# matches_fr.loc[matches_fr[home_name].isna(), home_name] = 0\n",
    "# matches_fr.loc[matches_fr[away_name].isna(), away_name] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(french_attempt_events.event_team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.13, 0.219] #optimal threshold determined in attempt_weighter.py for logistic-regression =0.219\n",
    "\n",
    "for thresh in thresholds:\n",
    "    home_weighted_attempts_counts = french_attempt_events[french_attempt_events.side == 1].groupby(\n",
    "        'id_odsp').french_attempt_weight.apply(lambda x: countt(x, threshold = thresh)) \n",
    "    away_weighted_attempts_counts = french_attempt_events[french_attempt_events.side == 2].groupby(\n",
    "        'id_odsp').french_attempt_weight.apply(lambda x: countt(x, threshold=thresh)) \n",
    "\n",
    "    matches_fr = pd.concat(\n",
    "        [matches_fr, home_weighted_attempts_counts],   axis=1)\n",
    "    matches_fr = matches_fr.rename(\n",
    "        {'french_attempt_weight': f\"home_counted_attempts_{str(thresh)}\"}, axis='columns')\n",
    "    matches_fr = pd.concat(\n",
    "        [matches_fr, away_weighted_attempts_counts],   axis=1)\n",
    "    matches_fr = matches_fr.rename(\n",
    "        {'french_attempt_weight': f\"away_counted_attempts_{str(thresh)}\"}, axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#home_weighted_attempts_counts.hist(bins = 14)\n",
    "#away_weighted_attempts_counts.hist(bins = 14)\n",
    "import copy  \n",
    "\n",
    "# m2 = copy.deepcopy(matches_fr)\n",
    "# m2 = m2['home_goals']\n",
    "\n",
    "# for thresh in [x/100 for x in range(0,100,1)]:\n",
    "#     home_weighted_attempts_counts = french_attempt_events[french_attempt_events.side == 1].groupby(\n",
    "#         'id_odsp').french_attempt_weight.apply(lambda x: countt(x, threshold=thresh))\n",
    "#     # away_weighted_attempts_counts = french_attempt_events[french_attempt_events.side == 2].groupby(\n",
    "#     #     'id_odsp').french_attempt_weight.apply(lambda x: countt(x, threshold=thresh))\n",
    "\n",
    "#     m2 = pd.concat(\n",
    "#         [m2, home_weighted_attempts_counts],   axis=1)\n",
    "#     m2 = m2.rename(\n",
    "#         {'french_attempt_weight': f\"{str(thresh)}\"}, axis='columns')\n",
    "#     # m2 = pd.concat(\n",
    "#     #     [m2, away_weighted_attempts_counts],   axis=1)\n",
    "#     # m2 = m2.rename(\n",
    "#     #     {'french_attempt_weight': f\"away_counted_attempts_{str(thresh)}\"}, axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2.corr(method='pearson')['home_goals'].iloc[2:83].plot(\n",
    "#     )\n",
    "# m2.corr(method='kendall')['home_goals'].iloc[2:83].plot(\n",
    "#    )\n",
    "# m2.corr(method='spearman')['home_goals'].iloc[2:83].plot(\n",
    "#     title='Correlation home_goals vs thresholded attempt counts', ylabel='correlation', xlabel='threshold value')\n",
    "\n",
    "# fig = m2.corr(method='spearman')['home_goals'].iloc[2:83].plot(\n",
    "#     title='Correlation home_goals vs thresholded attempt counts', ylabel='correlation', xlabel='threshold value').get_figure()\n",
    "\n",
    "# fig.savefig('correlation.png', dpi = 400)\n",
    "# #plt.title = 'correlation'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig.savefig('correlation.png', dpi=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m2.corr(method='spearman')['home_goals']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(set(french_attempt_events[(french_attempt_events.event_team == 'Marseille') & french_attempt_events.side ==1].id_odsp))\n",
    "\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for team in ['Lyon', 'Marseille', 'Paris Saint-Germain']: \n",
    "#     mars = home_weighted_attempts_counts[set(french_attempt_events[(\n",
    "#         french_attempt_events.event_team == team) & (french_attempt_events.side == 1)].id_odsp)]\n",
    "#     from scipy.stats import( kstest, poisson, norm)\n",
    "\n",
    "#     #print(kstest(mars.values, 'poisson',args = (mars.mean(),), alternative = 'greater', N=10000))\n",
    "\n",
    "#     #mars.hist()\n",
    "\n",
    "#     data = mars.values\n",
    "#     distris = ['norm', 'poisson']\n",
    "#     for distri in distris:\n",
    "#         stats.probplot(data, dist=distri, sparams=(mars.mean(),), plot=plt)\n",
    "#         plt.title(f\"qq-plot for {team}'s home_goals vs {distri} distribution\")\n",
    "#         plt.savefig(f\"{team}_qqplot_{distri}.png\", dpi = 400)\n",
    "#         plt.show()\n",
    "        \n",
    "\n",
    "#         print(f\"var = {mars.var()}, mean = {mars.mean()}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABOVE 'attempts-weight' columns are estimated using the LOGISTIC MODEL from ATTEMPT_WEIGHTER.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flevents = pd.read_csv('events_w_weighted_french_logistic.csv')\n",
    "# flevents = flevents[(flevents.id_odsp.isin(matches_fr.id_odsp)) & (\n",
    "#     flevents.event_type == 1) & (flevents.event_type2 != 15)]\n",
    "# flevents.groupby('id_odsp side'.split()).sum()\n",
    "\n",
    "# flhome_weighted_attempts = flevents[flevents.side == 1].groupby(\n",
    "#     'id_odsp').sum().french_attempt_weight\n",
    "\n",
    "# flaway_weighted_attempts = flevents[flevents.side == 2].groupby(\n",
    "#     'id_odsp').sum().french_attempt_weight\n",
    "\n",
    "# matches_fr = pd.concat([matches_fr, home_weighted_attempts],   axis=1)\n",
    "# matches_fr = matches_fr.rename(\n",
    "#     {'french_attempt_weight': 'home_weighted_attempts'}, axis='columns')\n",
    "# matches_fr = pd.concat([matches_fr, away_weighted_attempts],   axis=1)\n",
    "# matches_fr = matches_fr.rename(\n",
    "#     {'french_attempt_weight': 'away_weighted_attempts'}, axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # optimal threshold determined in attempt_weighter.py for logistic-regression\n",
    "# threshold = 0.13\n",
    "\n",
    "# flhome_weighted_attempts_counts = flevents[flevents.side == 1].groupby(\n",
    "#     'id_odsp').french_attempt_weight.apply(lambda x: countt(x, threshold=threshold))\n",
    "# flaway_weighted_attempts_counts = flevents[flevents.side == 2].groupby(\n",
    "#     'id_odsp').french_attempt_weight.apply(lambda x: countt(x, threshold=threshold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flhome_weighted_attempts_counts.hist(bins=15)\n",
    "#flaway_weighted_attempts_counts.hist(bins=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possession-proxy features: \n",
    "\n",
    "events that get or need possession to occur: \n",
    "attempt, offside, corner, freekick, passing\n",
    "\n",
    "events that are negatively associated with possession: \n",
    "foul, red card, yellow card, andball, penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass and assists analysis according to DSAA paper:\n",
    "\n",
    "[1. DONE ] total assist-volume: assist-methods 1,2,3,4              proxy for omega    (passing volume)\n",
    "[2. ] mean players passing volume (incl. substitutes)               mu_p  \n",
    "[3. ] variance of players passing volume                            sigma_p \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL ASSIST VOLUME PER MATCH\n",
    "\n",
    "home_total_assists = events_fr[(events_fr['assist_method'] != 0) & (\n",
    "    events_fr.side == 1)].groupby('id_odsp').count().assist_method\n",
    "\n",
    "away_total_assists = events_fr[(events_fr['assist_method'] != 0) & (\n",
    "    events_fr.side == 2)].groupby('id_odsp').count().assist_method\n",
    "\n",
    "matches_fr = pd.concat([matches_fr, home_total_assists],   axis=1)\n",
    "matches_fr = matches_fr.rename(\n",
    "     {'assist_method': 'home_total_assists'}, axis='columns')\n",
    "matches_fr = pd.concat([matches_fr, away_total_assists],   axis=1)\n",
    "matches_fr = matches_fr.rename(\n",
    "     {'assist_method': 'away_total_assists'}, axis='columns')\n",
    "\n",
    "matches_fr.loc[matches_fr.home_total_assists.isna(), 'home_total_assists'] = 0\n",
    "#sum(matches_fr.away_total_assists.isna())\n",
    "matches_fr.loc[matches_fr.away_total_assists.isna(), 'away_total_assists'] = 0\n",
    "# sum(matches_fr.away_total_assists.isna())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing the NaNs in weighted_attempts by replacing them with the respective teams' mean weighted_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_fr.isna().sum()\n",
    "\n",
    "home_nans = matches_fr[matches_fr.home_weighted_attempts.isna()]['ht']\n",
    "away_nans = matches_fr[matches_fr.away_weighted_attempts.isna()]['at']\n",
    "\n",
    "\n",
    "# homers = home_nans.values\n",
    "# for team in homers:\n",
    "#     matches_fr[matches_fr.ht == team].home_attempts.mean()\n",
    "#home_nans\n",
    "\n",
    "for game_id, team in home_nans.iteritems():\n",
    "    mean_att = matches_fr[matches_fr.ht == team].home_weighted_attempts.mean()\n",
    "    matches_fr.loc[matches_fr.id_odsp == game_id, 'home_weighted_attempts'] = mean_att\n",
    "for game_id, team in away_nans.iteritems():\n",
    "    mean_att = matches_fr[matches_fr['at'] == team].away_weighted_attempts.mean()\n",
    "    matches_fr.loc[matches_fr.id_odsp == game_id, 'away_weighted_attempts'] = mean_att\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing the NaNs in counted_attempts by replacing them with the respective teams' mean weighted_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#home_counted_attempts_0.13\taway_counted_attempts_0.13\thome_counted_attempts_0.219\taway_counted_attempts_0.219\n",
    "home_nans = matches_fr[matches_fr['home_counted_attempts_0.13'].isna()]['ht']\n",
    "away_nans = matches_fr[matches_fr['away_counted_attempts_0.13'].isna()]['at']\n",
    "\n",
    "for game_id, team in home_nans.iteritems():\n",
    "    mean_count = matches_fr[matches_fr.ht ==\n",
    "                            team]['home_counted_attempts_0.13'].mean()\n",
    "    mean_count = int(mean_count)\n",
    "    matches_fr.loc[matches_fr.id_odsp == game_id,        'home_counted_attempts_0.13'] = mean_count\n",
    "\n",
    "for game_id, team in away_nans.iteritems():\n",
    "    mean_count = matches_fr[matches_fr['at'] ==\n",
    "                          team]['away_counted_attempts_0.13'].mean()\n",
    "    mean_count = int(mean_count)\n",
    "    matches_fr.loc[matches_fr.id_odsp == game_id,  'away_counted_attempts_0.13'] = mean_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#home_counted_attempts_0.13\taway_counted_attempts_0.13\thome_counted_attempts_0.219\taway_counted_attempts_0.219\n",
    "home_nans = matches_fr[matches_fr['home_counted_attempts_0.219'].isna()]['ht']\n",
    "away_nans = matches_fr[matches_fr['away_counted_attempts_0.219'].isna()]['at']\n",
    "\n",
    "for game_id, team in home_nans.iteritems():\n",
    "    mean_count = matches_fr[matches_fr.ht ==\n",
    "                            team]['home_counted_attempts_0.219'].mean()\n",
    "    mean_count = int(mean_count)\n",
    "    matches_fr.loc[matches_fr.id_odsp == game_id,\n",
    "                   'home_counted_attempts_0.219'] = mean_count\n",
    "\n",
    "for game_id, team in away_nans.iteritems():\n",
    "    mean_count = matches_fr[matches_fr['at'] ==\n",
    "                            team]['away_counted_attempts_0.219'].mean()\n",
    "    mean_count = int(mean_count)\n",
    "    matches_fr.loc[matches_fr.id_odsp == game_id,\n",
    "                   'away_counted_attempts_0.219'] = mean_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matches_fr[matches_fr['away_counted_attempts_0.219'].isna()]['at']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding attempt_weights that are rounded to nearest integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_fr['home_weighted_attempts_discrete'] = matches_fr['home_weighted_attempts'].round(decimals = 0)\n",
    "matches_fr['away_weighted_attempts_discrete'] = matches_fr['away_weighted_attempts'].round(\n",
    "    decimals=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_assists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matches_fr['home_goals home_weighted_attempts'.split()].corr().values[0,1].round(decimals = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home_mean_assists = home_total_assists.copy()/11\n",
    "# away_mean_assists = away_total_assists.copy()/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# home_assist_variance = pd.DataFrame(events_fr[(events_fr['assist_method'] != 0) & (events_fr['side'] == 1)].groupby(\n",
    "#     'id_odsp event_team player2 '.split()).apply(lambda x: x.assist_method.count()).groupby('id_odsp').var())\n",
    "# home_assist_variance.columns = ['home_assist_variance']\n",
    "# home_assist_variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_assist_variance = pd.DataFrame(events_fr[(events_fr['assist_method'] != 0) & (events_fr['side'] == 1)].groupby(\n",
    "    'id_odsp event_team player2 '.split()).apply(lambda x: x.assist_method.count()).groupby('id_odsp').var())\n",
    "home_assist_variance.columns = ['home_assist_variance']\n",
    "\n",
    "away_assist_variance = pd.DataFrame(events_fr[(events_fr['assist_method'] != 0) & (events_fr['side'] == 2)].groupby(\n",
    "    'id_odsp event_team player2 '.split()).apply(lambda x: x.assist_method.count()).groupby('id_odsp').var())\n",
    "away_assist_variance.columns = ['away_assist_variance']\n",
    "\n",
    "matches_fr = pd.concat([matches_fr, home_assist_variance],   axis=1)\n",
    "matches_fr = matches_fr.rename(\n",
    "    {'assist_method': 'home_assist_variance'}, axis='columns')\n",
    "matches_fr = pd.concat([matches_fr, away_assist_variance],   axis=1)\n",
    "matches_fr = matches_fr.rename(\n",
    "    {'assist_method': 'away_assist_variance'}, axis='columns')\n",
    "\n",
    "# # changing nans to zeroes:\n",
    "matches_fr.loc[matches_fr['home_assist_variance'].isna(), 'home_assist_variance'] = 0\n",
    "matches_fr.loc[matches_fr['away_assist_variance'].isna(), 'away_assist_variance'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(matches_fr.home_offsides == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_odsp', 'link_odsp', 'adv_stats', 'date', 'league', 'season',\n",
       "       'country', 'ht', 'at', 'fthg', 'ftag', 'odd_h', 'odd_d', 'odd_a',\n",
       "       'odd_over', 'odd_under', 'odd_bts', 'odd_bts_n', 'home_attempts',\n",
       "       'away_attempts', 'home_redcard', 'away_redcard',\n",
       "       'home_penalty_conceded', 'away_penalty_conceded', 'home_sentoff',\n",
       "       'away_sentoff', 'home_corners_taken', 'away_corners_taken',\n",
       "       'home_fouls', 'away_fouls', 'home_free_kicks', 'away_free_kicks',\n",
       "       'home_handballs', 'away_handballs', 'home_offsides', 'away_offsides',\n",
       "       'home_own_goals', 'away_own_goals', 'home_yellowcards',\n",
       "       'away_yellowcards', 'home_weighted_attempts', 'away_weighted_attempts',\n",
       "       'home_counted_attempts_0.13', 'away_counted_attempts_0.13',\n",
       "       'home_counted_attempts_0.219', 'away_counted_attempts_0.219',\n",
       "       'home_total_assists', 'away_total_assists',\n",
       "       'home_weighted_attempts_discrete', 'away_weighted_attempts_discrete',\n",
       "       'home_assist_variance', 'away_assist_variance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_fr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding times of goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'home_goals'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-8932d20bbb24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhome_goal_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mextract_times\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mmatches_fr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmatches_fr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhome_goals\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'home_goal_times'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maway_goal_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mextract_times\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'home_goals'"
     ]
    }
   ],
   "source": [
    " \n",
    "ev = events_fr.copy()\n",
    "home_goal_times = ev[(ev.id_odsp.isin(matches_fr.id_odsp)) & (ev['is_goal'] == 1) & (ev['side'] == 1)].groupby('id_odsp') \n",
    "away_goal_times = ev[(ev.id_odsp.isin(matches_fr.id_odsp)) & (\n",
    "    ev['is_goal'] == 1) & (ev['side'] == 2)].groupby('id_odsp')\n",
    "\n",
    "\n",
    "def extract_times(row):\n",
    "    #print(row.time.values)\n",
    "    goal_times = []\n",
    "    if len(row.time.values) > 0:\n",
    "        for t in row.time.values:\n",
    "            goal_times.append(t)\n",
    "    else:\n",
    "        return []\n",
    "    return goal_times\n",
    "\n",
    "\n",
    "h = home_goal_times.apply(lambda x: extract_times(x))\n",
    "matches_fr.loc[matches_fr.home_goals > 0, 'home_goal_times'] = h\n",
    "\n",
    "a = away_goal_times.apply(lambda x: extract_times(x))\n",
    "matches_fr.loc[matches_fr.away_goals > 0, 'away_goal_times'] = a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating possession ensemble statistics: \n",
    "Possession = sum of attempts offsides, corners_taken and free_kicks in a match\n",
    "Dispossession = sum of fouls, redcards, yellowcards  in a match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_related_to_possession = 'attempts offsides corners_taken free_kicks '.split()\n",
    "events_related_to_dispossession = 'fouls redcard yellowcards'.split()\n",
    "\n",
    "home_possess, away_possess = [[side+event for event in events_related_to_possession] for side in ('home_', 'away_')]\n",
    "home_dispossess, away_dispossess = [\n",
    "    [side+event for event in events_related_to_dispossession] for side in ('home_', 'away_')]\n",
    "\n",
    "matches_fr['home_possessions'] = matches_fr[home_possess].sum(axis = 'columns')\n",
    "matches_fr['home_dispossessions'] = matches_fr[home_dispossess].sum(axis = 'columns')\n",
    "#matches_fr[home_possession]\n",
    "matches_fr['away_possessions'] = matches_fr[away_possess].sum(axis='columns')\n",
    "matches_fr['away_dispossessions'] = matches_fr[away_dispossess].sum(\n",
    "    axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_fr['home_possession_percentage'] = 100 * matches_fr['home_possessions'] / (matches_fr['home_possessions'] + matches_fr['away_possessions'] ).round(decimals = 2)\n",
    "matches_fr['away_possession_percentage'] = 100 * matches_fr['away_possessions'] / \\\n",
    "    (matches_fr['home_possessions'] +\n",
    "     matches_fr['away_possessions'])\n",
    "\n",
    "matches_fr['home_possdis_percentage'] = 100 *(matches_fr['home_possessions'] - \\\n",
    "                                         matches_fr['home_dispossessions']) / (matches_fr['home_possessions'] + matches_fr['away_possessions'] - matches_fr['home_dispossessions'] - matches_fr['away_dispossessions'])\n",
    "matches_fr['away_possdis_percentage'] = 100 * (matches_fr['away_possessions'] -\n",
    "                                               matches_fr['away_dispossessions']) / (matches_fr['home_possessions'] + matches_fr['away_possessions'] - matches_fr['home_dispossessions'] - matches_fr['away_dispossessions'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_index(x, side ):\n",
    "    #print(x)\n",
    "    if side ==1:\n",
    "\n",
    "        home_assists = np.clip(x['home_total_assists'], a_min=0.01, a_max=20)    \n",
    "        home_std = np.clip(x['home_assist_variance'], a_min=0.01, a_max=10) \n",
    "        home_h_index = 2 / ((1/home_assists) + (1/home_std))\n",
    "    \n",
    "        return home_h_index \n",
    "    elif side ==2:\n",
    "        away_assists = np.clip(x['away_total_assists'], a_min=0.01, a_max = 20)\n",
    "        away_std = np.clip(x['away_assist_variance'], a_min=0.01, a_max = 10)\n",
    "        away_h_index = 2 / ((1/away_assists) + (1/away_std))\n",
    "\n",
    "        return away_h_index\n",
    "    else: \n",
    "        error = print('CORRECT SIDE NOT SPECIFIED WHEN CALLING H-INDEX FUNCTION')\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_h_index = matches_fr.apply(lambda x: h_index(x, side = 1), axis = 'columns')\n",
    "away_h_index = matches_fr.apply(lambda x: h_index(x, side=2), axis='columns')\n",
    "\n",
    "matches_fr['home_h_index'] = home_h_index\n",
    "matches_fr['away_h_index'] = away_h_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_fr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOTTING CORRELATIONS OF ALL VARIABLES WITH THE ENDING SCORES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "columns_of_interest = ['home_goals', 'away_goals','home_attempts',\n",
    "'away_attempts', 'home_redcard', 'away_redcard',\n",
    "'home_penalty_conceded', 'away_penalty_conceded', 'home_sentoff',\n",
    "'away_sentoff', 'home_corners_taken', 'away_corners_taken',\n",
    "'home_fouls', 'away_fouls', 'home_free_kicks', 'away_free_kicks',\n",
    "'home_handballs', 'away_handballs', 'home_offsides', 'away_offsides',\n",
    "'home_own_goals', 'away_own_goals', 'home_yellowcards',\n",
    "                       'away_yellowcards', 'home_weighted_attempts', 'away_weighted_attempts', \n",
    "                       'home_weighted_attempts_discrete', 'away_weighted_attempts_discrete', 'home_counted_attempts_0.13', 'away_counted_attempts_0.13',\n",
    "                       'home_counted_attempts_0.219', 'away_counted_attempts_0.219',\n",
    "'home_total_assists', 'away_total_assists', 'home_assist_variance',\n",
    "'away_assist_variance', 'home_goal_times', 'away_goal_times',\n",
    "                       'home_possessions', 'home_dispossessions', 'away_possessions', 'home_possession_percentage',\n",
    "                       'away_possession_percentage', 'home_possdis_percentage',\n",
    "                       'away_possdis_percentage',\n",
    "                       'away_dispossessions', 'home_h_index', 'away_h_index']\n",
    "\n",
    "#matches_fr.plot.scatter(y='home_goals',\n",
    "                #x='home_corners_taken')\n",
    "#sns.regplot(matches_fr.home_goals, matches_fr.home_corners_taken, color='blue')\n",
    "#matches_fr['home_goals home_sentoff'.split()].corr('pearson')\n",
    "\n",
    "matches_fr[columns_of_interest].corr(method = 'pearson')\n",
    "#sns.pairplot(matches_fr[columns_of_interest], y_vars=['home_weighted_attempts',                                                      'away_weighted_attempts', 'home_possessions', 'away_possessions'], x_vars=['home_goals', 'away_goals'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a   = pd.concat([matches_fr.away_goals, np.floor(matches_fr.away_weighted_attempts)], axis = 1) \n",
    "a.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot_correlation(col_names, data=matches_fr):\n",
    "    x_name,y_name = col_names\n",
    "    correlation = matches_fr[[x_name, y_name]].corr().values[0, 1].round(decimals=3)\n",
    "    sns.stripplot(data=data, x = x_name, y = y_name)\n",
    "    #plt.text(3+0.2, 4.5, f\"Pearson-correlation: {correlation}\", horizontalalignment='left',\n",
    "             #size='medium', color='black', weight='semibold')\n",
    "    plt.title(f\"({x_name}, {y_name}): Pearson-correlation: {correlation}\", weight = 'bold')\n",
    "\n",
    "    return plt\n",
    "    #plt.show()\n",
    "\n",
    "relevant_columns = 'attempts redcard penalty_conceded weighted_attempts weighted_attempts_discrete total_assists assist_variance possessions h_index'.split()\n",
    "\n",
    "relevant_home_names = [('home_goals','home_'+name) for name in relevant_columns] \n",
    "relevant_away_names = [('away_goals','away_'+name) for name in relevant_columns ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in relevant_columns:\n",
    "#     x_name_home, y_name_home = ('home_goals', 'home_'+name)\n",
    "#     x_name_away, y_name_away = ('away_goals', 'away_'+name)\n",
    "#     data = matches_fr\n",
    "#     figure, axes = plt.subplots(nrows = 1, ncols = 2)\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     sns.stripplot(data=data, x=x_name_home, y=y_name_away)\n",
    "#     plt.ylabel(y_name_home)\n",
    "#     plt.xlabel(x_name_home)\n",
    "#     correlation = matches_fr[[x_name_home, y_name_home]\n",
    "#                              ].corr().values[0, 1].round(decimals=3)\n",
    "#     plt.title(f\"home goals \\n vs \\n{y_name_home} \\n \\n correlation = {correlation}\" , weight = 'bold')\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     sns.stripplot(data=data, x=x_name_away, y=y_name_away)\n",
    "#     plt.ylabel(y_name_away)\n",
    "#     plt.xlabel(x_name_away)\n",
    "#     correlation = matches_fr[[x_name_away, y_name_away]\n",
    "#                              ].corr().values[0, 1].round(decimals=3)\n",
    "#     plt.title(f\"away goals \\n vs \\n {y_name_away} \\n \\n correlation = {correlation}\", weight = 'bold')\n",
    "     \n",
    "    \n",
    "#     figure.tight_layout(pad=1)\n",
    "\n",
    "#     current = os.getcwd()\n",
    "#     #os.mkdir(current+'\\\\plots\\\\')\n",
    "#     fname = current + '\\\\plots\\\\' + name + '.png' \n",
    "#     print(f\"fname = {fname}\")\n",
    "#     plt.savefig(fname = fname, dpi = 300)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "def save_data(data, name):\n",
    "    curr_time = str(time.monotonic())[:6]\n",
    "    name+=curr_time\n",
    "    name+='.csv'\n",
    "    data.to_csv(name)\n",
    "\n",
    "#save_data(matches_fr, 'processed_french_matches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_fr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_fr[\"ht_cat\"] = pd.Categorical(matches_fr['ht']).codes\n",
    "matches_fr[\"at_cat\"] = pd.Categorical(matches_fr['at']).codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add round labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_participants_per_round(data, round, cat = False):\n",
    "    # based on round label:\n",
    "    # return the set of all teams that played in this round\n",
    "    if cat == False: \n",
    "        home = set(data[data[\"round_labels\"] == round][\"ht\"])\n",
    "        away = set(data[data[\"round_labels\"] == round][\"at\"])\n",
    "        participants = home.union(away)\n",
    "    else: \n",
    "        home = set(data[data[\"round_labels_cat\"] == round][\"ht_cat\"])\n",
    "        away = set(data[data[\"round_labels_cat\"] == round][\"at_cat\"])\n",
    "        participants = home.union(away)\n",
    "    return list(participants)\n",
    "\n",
    "\n",
    "def get_participants(data, cat = False):\n",
    "    if cat == False:\n",
    "        round_labels = data[\"round_labels\"]\n",
    "    else: \n",
    "        round_labels = data['round_labels_cat']\n",
    "    result = []\n",
    "    for i in round_labels:\n",
    "        if i % 20:\n",
    "            print(\"adding participants\", i)\n",
    "        if cat == False:\n",
    "            sub = get_participants_per_round(data, i,cat)\n",
    "        else:\n",
    "            sub = get_participants_per_round(data, i, cat)\n",
    "        result.append(sub)\n",
    "    if cat == False: \n",
    "        data[\"participants\"] = result\n",
    "    else: \n",
    "        data['participants_cat'] = result\n",
    "    print(f\"Added participants, categorical = {cat}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def construct_round_labels(tau, data):\n",
    "    diff = pd.DataFrame(tau).diff(1)\n",
    "    diff.iloc[0] = tau[0]\n",
    "    diff = list(i for [i] in diff.values)\n",
    "    diff.append(len(data)-tau[-1])\n",
    "\n",
    "    result = []\n",
    "    for (i, j) in enumerate(diff):\n",
    "        temp = [i]*int(j)\n",
    "        result.append(temp)\n",
    "    return [item + 1 for sublist in result for item in sublist]\n",
    "\n",
    "\n",
    "def add_rounds(data, categorical_names = False):\n",
    "    # input: match-participation data (HomeTeamCat, AwayTeamCat)\n",
    "    # return: a series of indices tau that define start of new round (end of old round)\n",
    "    # tau_0 = 0\n",
    "\n",
    "    seen = set()\n",
    "    if categorical_names == False:\n",
    "        home = data[\"ht\"]\n",
    "        away = data[\"at\"]\n",
    "    else:\n",
    "        home= data['ht_cat']\n",
    "        away = data['at_cat']\n",
    "\n",
    "    tau = []\n",
    "    participants = []\n",
    "    for i in range(len(data)):\n",
    "        if home.iloc[i] in seen or away.iloc[i] in seen:\n",
    "            print(\"seen before: \")\n",
    "            participants.append([j for j in seen])\n",
    "            seen = set()\n",
    "            tau.append(i)\n",
    "\n",
    "        else:\n",
    "            seen.add(home.iloc[i])\n",
    "            seen.add(away.iloc[i])\n",
    "\n",
    "    # creates list of round-labels\n",
    "    round_labels = construct_round_labels(tau, data)\n",
    "    if categorical_names == False:\n",
    "        data[\"round_labels\"] = round_labels\n",
    "    # data\"participants\"] = participants[\n",
    "        data = get_participants(data)\n",
    "    else:\n",
    "        data[\"round_labels_cat\"] = round_labels\n",
    "        data = get_participants(data, cat = True)\n",
    "   # data[\"participants\"] =\n",
    "    return data\n",
    "\n",
    "\n",
    "matches_fr = add_rounds(matches_fr, categorical_names=False)\n",
    "\n",
    "matches_fr = add_rounds(matches_fr, categorical_names= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, name):\n",
    "    curr_time = str(time.monotonic())[:6]\n",
    "    name += curr_time\n",
    "    name += '.csv'\n",
    "    data.to_csv(name)\n",
    "\n",
    "#save_data(matches_fr, 'matches_fr_labeled')\n",
    "\n",
    "def pickle_data(data, name):\n",
    "    curr_time = str(time.monotonic())[:6]\n",
    "    name += curr_time\n",
    "    name += '.pkl'\n",
    "    data.to_pickle(name)\n",
    "    print(f\"pickled data as {name}\")\n",
    "\n",
    "\n",
    "#pickle_data(matches_fr, 'matches_fr_labeled')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column with a binary marker for teams that have been seen for the first time in this data-set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# participants = []\n",
    "# home_first_occurence= []\n",
    "# away_first_occurence= []\n",
    "# for i in range(len(data)):\n",
    "#     if home.iloc[i] in seen or away.iloc[i] in seen:\n",
    "#         #print(\"seen before: \")\n",
    "#         participants.append([j for j in seen])\n",
    "#         seen = set()\n",
    "#         tau.append(i)\n",
    "\n",
    "#     else:\n",
    "#         seen.add(home.iloc[i])\n",
    "#         seen.add(away.iloc[i])\n",
    "matches_fr.sort_values(by='date')\n",
    "index = range(len(matches_fr))\n",
    "matches_fr['order'] = index \n",
    "#matches_fr['home_first_seen'] = 0\n",
    "#matches_fr['away_first_seen']= 0\n",
    "seen = set()\n",
    "home_first_seen = []\n",
    "away_first_seen = []\n",
    "for  i in range(len(matches_fr)):\n",
    "    \n",
    "    home = matches_fr.iloc[i]['ht']\n",
    "    away = matches_fr.iloc[i]['at']\n",
    "    if home not in seen: \n",
    "        seen.add(home)\n",
    "        home_first_seen.append(1)\n",
    "    else:\n",
    "        home_first_seen.append(0)\n",
    "    if away not in seen:\n",
    "        seen.add(away)\n",
    "        away_first_seen.append(1)\n",
    "    else:\n",
    "        away_first_seen.append(0)\n",
    "\n",
    " \n",
    "matches_fr['home_first_seen'] = home_first_seen\n",
    "matches_fr['away_first_seen'] = away_first_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(matches_fr, 'matches_fr_labeled')\n",
    "pickle_data(matches_fr, name = 'matches_fr_labeled')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matches_fr.columns"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d49a995e02e5c12d4aea286f1be347287d020919acd83fc9c32cf543e5b414b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
